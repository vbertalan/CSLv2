{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610bf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039b1a66bbc44fb492de74aa2b1d9e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: resultadosPC/causal_relations.csv (12 rela√ß√µes causais)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compilation failed, linking failed</td>\n",
       "      <td>compilation failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>compilation failed, linking failed, network ti...</td>\n",
       "      <td>compilation failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>compilation failed, linking failed, network ti...</td>\n",
       "      <td>compilation failed, network timeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disk full, compilation failed, linking failed</td>\n",
       "      <td>disk full, compilation failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disk full, compilation failed, linking failed,...</td>\n",
       "      <td>compilation failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0                 compilation failed, linking failed   \n",
       "1  compilation failed, linking failed, network ti...   \n",
       "2  compilation failed, linking failed, network ti...   \n",
       "3      disk full, compilation failed, linking failed   \n",
       "4  disk full, compilation failed, linking failed,...   \n",
       "\n",
       "                                target  \n",
       "0                   compilation failed  \n",
       "1                   compilation failed  \n",
       "2  compilation failed, network timeout  \n",
       "3        disk full, compilation failed  \n",
       "4                   compilation failed  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.utils.cit import chisq\n",
    "import numpy as np\n",
    "\n",
    "def read_log_lines(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def build_windowed_dataset(log_lines, window_size=5):\n",
    "    windows = []\n",
    "    for i in range(len(log_lines) - window_size + 1):\n",
    "        window = log_lines[i:i+window_size]\n",
    "        windows.append(set(window))  # evita repeti√ß√£o dentro da janela\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_matrix = mlb.fit_transform(windows)\n",
    "    df = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
    "    return df, mlb.classes_\n",
    "\n",
    "def run_pc_and_export_csv(df, variable_names, output_path=\"pc_result.csv\", alpha=0.01):\n",
    "    X = df.to_numpy().astype(int)\n",
    "    cg = pc(data=X, alpha=alpha, indep_test=\"chisq\", uc_rule=0, verbose=False)\n",
    "\n",
    "    edges = []\n",
    "    n_vars = len(variable_names)\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_vars):\n",
    "            if cg.G.graph[i, j] == -1 and cg.G.graph[j, i] == 1:\n",
    "                # i ‚Üí j\n",
    "                edges.append((variable_names[i], variable_names[j]))\n",
    "\n",
    "    df_edges = pd.DataFrame(edges, columns=[\"source\", \"target\"])\n",
    "    df_edges.to_csv(output_path, index=False)\n",
    "    print(f\"Arquivo salvo em: {output_path} ({len(df_edges)} rela√ß√µes causais)\")\n",
    "    return df_edges\n",
    "\n",
    "\n",
    "# === Configura√ß√µes ===\n",
    "log_path = \"logs/logs_teste.log\"  # exemplo: \"/home/user/meu_log.log\"\n",
    "window_size = 5\n",
    "alpha = 0.01\n",
    "output_path = \"resultadosPC/causal_relations.csv\"\n",
    "\n",
    "# === Processamento ===\n",
    "log_lines = read_log_lines(log_path)\n",
    "df, variable_names = build_windowed_dataset(log_lines, window_size)\n",
    "df_result = run_pc_and_export_csv(df, variable_names, output_path, alpha=alpha)\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Window size escolhido: 30\n",
      "üìä 10819 janelas √ó 100 eventos √∫nicos ‚Üí raz√£o amostra/feature = 108.19\n",
      "üîé N√≠vel de confian√ßa estat√≠stica: ALTA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37a0511601a402ca3b8a9709fe7ff65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Arquivo CSV salvo em: relacoes_causais.csv\n",
      "üìù Relat√≥rio salvo em: relatorio.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awk symbol lookup error awk undefined symbol</td>\n",
       "      <td>cccp invalid option</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot open directory dhcp</td>\n",
       "      <td>find no such file or directory</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cannot open directory grub d</td>\n",
       "      <td>cannot open directory dhcp</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc error unrecognized command line option</td>\n",
       "      <td>no such file or directory</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ccppc linker input file unused because linking...</td>\n",
       "      <td>cccp invalid option</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0       awk symbol lookup error awk undefined symbol   \n",
       "1                         cannot open directory dhcp   \n",
       "2                       cannot open directory grub d   \n",
       "3          cc error unrecognized command line option   \n",
       "4  ccppc linker input file unused because linking...   \n",
       "\n",
       "                           target  relation  \n",
       "0             cccp invalid option  directed  \n",
       "1  find no such file or directory  directed  \n",
       "2      cannot open directory dhcp  directed  \n",
       "3       no such file or directory  directed  \n",
       "4             cccp invalid option  directed  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.utils.cit import chisq\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def read_log_lines(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def choose_window_size(log_lines, frequent_templates, min_samples_per_feature=5, max_window=30):\n",
    "    n_features = len(frequent_templates)\n",
    "    n_lines = len(log_lines)\n",
    "\n",
    "    if n_features == 0:\n",
    "        raise ValueError(\"Nenhum evento com frequ√™ncia suficiente.\")\n",
    "\n",
    "    for window_size in range(max_window, 1, -1):\n",
    "        n_samples = n_lines - window_size + 1\n",
    "        if n_samples >= min_samples_per_feature * n_features:\n",
    "            return window_size\n",
    "    return 2\n",
    "\n",
    "def build_windowed_dataset(log_lines, window_size=None, min_freq=5):\n",
    "    counts = Counter(log_lines)\n",
    "    frequent_templates = {tpl for tpl, freq in counts.items() if freq >= min_freq}\n",
    "    filtered_lines = [line for line in log_lines if line in frequent_templates]\n",
    "\n",
    "    if len(frequent_templates) == 0:\n",
    "        raise ValueError(\"Nenhum template sobreviveu ao filtro de frequ√™ncia.\")\n",
    "\n",
    "    if window_size is None:\n",
    "        window_size = choose_window_size(filtered_lines, frequent_templates)\n",
    "\n",
    "    windows = []\n",
    "    for i in range(len(filtered_lines) - window_size + 1):\n",
    "        window = filtered_lines[i:i+window_size]\n",
    "        windows.append(set(window))\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_matrix = mlb.fit_transform(windows)\n",
    "    df = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
    "\n",
    "    n_samples = df.shape[0]\n",
    "    n_features = df.shape[1]\n",
    "    ratio = n_samples / n_features if n_features else 0\n",
    "\n",
    "    if ratio >= 10:\n",
    "        confidence = \"ALTA\"\n",
    "    elif ratio >= 5:\n",
    "        confidence = \"MODERADA\"\n",
    "    else:\n",
    "        confidence = \"BAIXA\"\n",
    "\n",
    "    return df, mlb.classes_, window_size, n_samples, n_features, ratio, confidence\n",
    "\n",
    "def run_pc_and_export(df, variable_names, csv_path=\"pc_result.csv\", report_path=\"pc_report.txt\", alpha=0.01):\n",
    "    X = df.to_numpy().astype(int)\n",
    "    cg = pc(data=X, alpha=alpha, indep_test=\"chisq\", uc_rule=0, verbose=False)\n",
    "\n",
    "    directed = []\n",
    "    bidirectional = []\n",
    "    undirected = []\n",
    "\n",
    "    n_vars = len(variable_names)\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_vars):\n",
    "            if i == j:\n",
    "                continue\n",
    "            a = cg.G.graph[i, j]\n",
    "            b = cg.G.graph[j, i]\n",
    "            if a == -1 and b == 1:\n",
    "                directed.append((variable_names[i], variable_names[j]))\n",
    "            elif a == 1 and b == 1:\n",
    "                bidirectional.append((variable_names[i], variable_names[j]))\n",
    "            elif a == -1 and b == -1:\n",
    "                undirected.append((variable_names[i], variable_names[j]))\n",
    "\n",
    "    # Criar dataframe completo\n",
    "    df_all = pd.DataFrame(directed + bidirectional + undirected,\n",
    "                          columns=[\"source\", \"target\"])\n",
    "    df_all[\"relation\"] = ([\"directed\"] * len(directed) +\n",
    "                          [\"bidirectional\"] * len(bidirectional) +\n",
    "                          [\"undirected\"] * len(undirected))\n",
    "\n",
    "    df_all.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Criar relat√≥rio\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"=== Relat√≥rio de Causalidade ===\\n\")\n",
    "        f.write(f\"Total de vari√°veis analisadas: {n_vars}\\n\")\n",
    "        f.write(f\"Arestas direcionadas: {len(directed)}\\n\")\n",
    "        f.write(f\"Arestas bidirecionais: {len(bidirectional)}\\n\")\n",
    "        f.write(f\"Arestas n√£o-direcionadas: {len(undirected)}\\n\")\n",
    "        f.write(f\"\\nCSV salvo em: {csv_path}\\n\")\n",
    "\n",
    "    print(f\"üíæ Arquivo CSV salvo em: {csv_path}\")\n",
    "    print(f\"üìù Relat√≥rio salvo em: {report_path}\")\n",
    "    return df_all\n",
    "\n",
    "#log_path = \"logs/logs_teste.log\"\n",
    "log_path = \"logs/part_3.log\"\n",
    "csv_path = \"relacoes_causais3.csv\"\n",
    "report_path = \"relatorio3.txt\"\n",
    "alpha = 0.01\n",
    "\n",
    "log_lines = read_log_lines(log_path)\n",
    "\n",
    "# Montar dataset\n",
    "df, variable_names, window_size, n_samples, n_features, ratio, confidence = build_windowed_dataset(\n",
    "    log_lines, window_size=None, min_freq=5\n",
    ")\n",
    "\n",
    "print(f\"üìè Window size escolhido: {window_size}\")\n",
    "print(f\"üìä {n_samples} janelas √ó {n_features} eventos √∫nicos ‚Üí raz√£o amostra/feature = {ratio:.2f}\")\n",
    "print(f\"üîé N√≠vel de confian√ßa estat√≠stica: {confidence}\")\n",
    "\n",
    "# Rodar algoritmo PC e salvar resultados\n",
    "df_result = run_pc_and_export(\n",
    "    df,\n",
    "    variable_names,\n",
    "    csv_path,\n",
    "    report_path,\n",
    "    alpha\n",
    ")\n",
    "\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c131d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Window size escolhido: 30\n",
      "üìä 9446 janelas √ó 63 eventos √∫nicos ‚Üí raz√£o amostra/feature = 149.94\n",
      "üîé N√≠vel de confian√ßa estat√≠stica: ALTA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19518ff1cb5e421097e766dd1c4090fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Arquivo CSV salvo em: relacoes_causais221.csv\n",
      "üìù Relat√≥rio salvo em: relatorio221.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attributeerror type object has no attribute</td>\n",
       "      <td>cp cannot copy cyclic symbolic link</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attributeerror type object has no attribute</td>\n",
       "      <td>find docker permission denied</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attributeerror type object has no attribute</td>\n",
       "      <td>valueerror jira not promoted because built in ...</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awk symbol lookup error awk undefined symbol</td>\n",
       "      <td>jq error at stdin null null has no keys</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cannot open directory dhcp</td>\n",
       "      <td>cannot open directory grub d</td>\n",
       "      <td>directed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source  \\\n",
       "0   attributeerror type object has no attribute   \n",
       "1   attributeerror type object has no attribute   \n",
       "2   attributeerror type object has no attribute   \n",
       "3  awk symbol lookup error awk undefined symbol   \n",
       "4                    cannot open directory dhcp   \n",
       "\n",
       "                                              target  relation  \n",
       "0                cp cannot copy cyclic symbolic link  directed  \n",
       "1                      find docker permission denied  directed  \n",
       "2  valueerror jira not promoted because built in ...  directed  \n",
       "3            jq error at stdin null null has no keys  directed  \n",
       "4                       cannot open directory grub d  directed  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.utils.cit import chisq\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def read_log_lines(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def choose_window_size(log_lines, frequent_templates, min_samples_per_feature=5, max_window=30):\n",
    "    n_features = len(frequent_templates)\n",
    "    n_lines = len(log_lines)\n",
    "\n",
    "    if n_features == 0:\n",
    "        raise ValueError(\"Nenhum evento com frequ√™ncia suficiente.\")\n",
    "\n",
    "    for window_size in range(max_window, 1, -1):\n",
    "        n_samples = n_lines - window_size + 1\n",
    "        if n_samples >= min_samples_per_feature * n_features:\n",
    "            return window_size\n",
    "    return 2\n",
    "\n",
    "def build_windowed_dataset(log_lines, window_size=None, min_freq=5):\n",
    "    counts = Counter(log_lines)\n",
    "    frequent_templates = {tpl for tpl, freq in counts.items() if freq >= min_freq}\n",
    "    filtered_lines = [line for line in log_lines if line in frequent_templates]\n",
    "\n",
    "    if len(frequent_templates) == 0:\n",
    "        raise ValueError(\"Nenhum template sobreviveu ao filtro de frequ√™ncia.\")\n",
    "\n",
    "    if window_size is None:\n",
    "        window_size = choose_window_size(filtered_lines, frequent_templates)\n",
    "\n",
    "    windows = []\n",
    "    for i in range(len(filtered_lines) - window_size + 1):\n",
    "        window = filtered_lines[i:i+window_size]\n",
    "        windows.append(set(window))\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_matrix = mlb.fit_transform(windows)\n",
    "    df = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
    "\n",
    "    n_samples = df.shape[0]\n",
    "    n_features = df.shape[1]\n",
    "    ratio = n_samples / n_features if n_features else 0\n",
    "\n",
    "    if ratio >= 10:\n",
    "        confidence = \"ALTA\"\n",
    "    elif ratio >= 5:\n",
    "        confidence = \"MODERADA\"\n",
    "    else:\n",
    "        confidence = \"BAIXA\"\n",
    "\n",
    "    return df, mlb.classes_, window_size, n_samples, n_features, ratio, confidence\n",
    "\n",
    "def run_pc_and_export(df, variable_names, csv_path=\"pc_result.csv\", report_path=\"pc_report.txt\", alpha=0.01):\n",
    "    X = df.to_numpy().astype(int)\n",
    "    cg = pc(data=X, alpha=alpha, indep_test=\"chisq\", uc_rule=0, verbose=False)\n",
    "\n",
    "    directed = []\n",
    "    bidirectional = []\n",
    "    undirected = []\n",
    "\n",
    "    n_vars = len(variable_names)\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_vars):\n",
    "            if i == j:\n",
    "                continue\n",
    "            a = cg.G.graph[i, j]\n",
    "            b = cg.G.graph[j, i]\n",
    "            if a == -1 and b == 1:\n",
    "                directed.append((variable_names[i], variable_names[j]))\n",
    "            elif a == 1 and b == 1:\n",
    "                bidirectional.append((variable_names[i], variable_names[j]))\n",
    "            elif a == -1 and b == -1:\n",
    "                undirected.append((variable_names[i], variable_names[j]))\n",
    "\n",
    "    # Criar dataframe completo\n",
    "    df_all = pd.DataFrame(directed + bidirectional + undirected,\n",
    "                          columns=[\"source\", \"target\"])\n",
    "    df_all[\"relation\"] = ([\"directed\"] * len(directed) +\n",
    "                          [\"bidirectional\"] * len(bidirectional) +\n",
    "                          [\"undirected\"] * len(undirected))\n",
    "\n",
    "    df_all.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Criar relat√≥rio\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"=== Relat√≥rio de Causalidade ===\\n\")\n",
    "        f.write(f\"Total de vari√°veis analisadas: {n_vars}\\n\")\n",
    "        f.write(f\"Arestas direcionadas: {len(directed)}\\n\")\n",
    "        f.write(f\"Arestas bidirecionais: {len(bidirectional)}\\n\")\n",
    "        f.write(f\"Arestas n√£o-direcionadas: {len(undirected)}\\n\")\n",
    "        f.write(f\"\\nCSV salvo em: {csv_path}\\n\")\n",
    "\n",
    "    print(f\"üíæ Arquivo CSV salvo em: {csv_path}\")\n",
    "    print(f\"üìù Relat√≥rio salvo em: {report_path}\")\n",
    "    return df_all\n",
    "\n",
    "#log_path = \"logs/logs_teste.log\"\n",
    "log_path = \"logs/part_221.log\"\n",
    "csv_path = \"relacoes_causais221.csv\"\n",
    "report_path = \"relatorio221.txt\"\n",
    "alpha = 0.01\n",
    "\n",
    "log_lines = read_log_lines(log_path)\n",
    "\n",
    "# Montar dataset\n",
    "df, variable_names, window_size, n_samples, n_features, ratio, confidence = build_windowed_dataset(\n",
    "    log_lines, window_size=None, min_freq=5\n",
    ")\n",
    "\n",
    "print(f\"üìè Window size escolhido: {window_size}\")\n",
    "print(f\"üìä {n_samples} janelas √ó {n_features} eventos √∫nicos ‚Üí raz√£o amostra/feature = {ratio:.2f}\")\n",
    "print(f\"üîé N√≠vel de confian√ßa estat√≠stica: {confidence}\")\n",
    "\n",
    "# Rodar algoritmo PC e salvar resultados\n",
    "df_result = run_pc_and_export(\n",
    "    df,\n",
    "    variable_names,\n",
    "    csv_path,\n",
    "    report_path,\n",
    "    alpha\n",
    ")\n",
    "\n",
    "df_result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
