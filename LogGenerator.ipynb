{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9603250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file successfully generated in logs.log\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate random timestamps with milliseconds difference\n",
    "def random_timestamp(start, max_millisec_increment):\n",
    "    increment = timedelta(milliseconds=random.randint(1, max_millisec_increment))\n",
    "    return start + increment\n",
    "\n",
    "# Generate fictitious log lines with timestamps\n",
    "def generate_log_line(i, timestamp):\n",
    "    events = [\n",
    "        \"User logged in\",\n",
    "        \"Session started successfully\",\n",
    "        \"Connection error\",\n",
    "        \"Reconnection attempt\",\n",
    "        \"Database query\",\n",
    "        \"Database updated\",\n",
    "        \"Security alert issued\",\n",
    "        \"Backup started\",\n",
    "        \"Backup completed\",\n",
    "        \"Configuration file loaded\",\n",
    "        \"User logged out\",\n",
    "        \"Apache server restarted\",\n",
    "        \"RAM memory exceeding limit\",\n",
    "        \"Low disk space\",\n",
    "        \"Cache cleared successfully\"\n",
    "    ]\n",
    "    event = random.choice(events)\n",
    "    return f\"{timestamp.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]} - {event} [ID: {i}]\"\n",
    "\n",
    "# Define timestamp start\n",
    "start_time = datetime(2023, 1, 1, 0, 0, 0)\n",
    "\n",
    "# Create 200 log lines with timestamps spaced by milliseconds\n",
    "num_lines = 200\n",
    "logs = []\n",
    "current_time = start_time\n",
    "for i in range(num_lines):\n",
    "    current_time = random_timestamp(current_time, 5000)  # max 5 seconds increment (5000 ms)\n",
    "    logs.append(generate_log_line(i, current_time))\n",
    "\n",
    "# Insert explicit causal pairs with dynamic line difference\n",
    "for i in range(0, num_lines - 10, 20):  # insert a causal pair every 20 lines\n",
    "    causal_gap = random.randint(1, 5)  # causal event occurs 1 to 5 lines later\n",
    "    logs[i] = f\"{logs[i][:23]} - User logged in [ID: {i}]\"\n",
    "    logs[i + causal_gap] = f\"{logs[i + causal_gap][:23]} - Session started successfully [ID: {i+causal_gap}]\"\n",
    "\n",
    "# Save log file\n",
    "with open(\"logs.log\", \"w\") as f:\n",
    "    for log_entry in logs:\n",
    "        f.write(log_entry + \"\\n\")\n",
    "\n",
    "print(\"Log file successfully generated in logs.log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e979702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "NUM_SEQUENCES = 100  # scale up\n",
    "EVENT_POOL = list(string.ascii_uppercase)  # Events A-Z\n",
    "# Causal chains\n",
    "causal_rules = [\n",
    "    ['A', 'B', 'C'],\n",
    "    ['D', 'E'],\n",
    "    ['F', 'G', 'H'],\n",
    "]\n",
    "# Common cause pattern: H → I and H → J (but no direct I :flecha_esquerda_direita: J)\n",
    "common_causes = [('H', ['I', 'J'])]\n",
    "# Spurious reversed causality: J appears before I\n",
    "reversed_pairs = [('K', 'L')]  # L appears before K in sequences\n",
    "# Independent noisy events\n",
    "noise_events = ['X', 'Y', 'Z']\n",
    "def generate_sequence():\n",
    "    sequence = []\n",
    "    # Real causal chains\n",
    "    for chain in causal_rules:\n",
    "        sub = []\n",
    "        for e in chain:\n",
    "            if random.random() > 0.1:  # 10% chance to drop event\n",
    "                sub.append(e)\n",
    "        sequence.extend(sub)\n",
    "    # Common cause-based correlations\n",
    "    for cause, effects in common_causes:\n",
    "        sequence.append(cause)\n",
    "        for e in effects:\n",
    "            if random.random() > 0.05:\n",
    "                sequence.append(e)\n",
    "    # Spurious reversed causality\n",
    "    for a, b in reversed_pairs:\n",
    "        sequence.append(b)\n",
    "        sequence.append(a)\n",
    "    # Add noise\n",
    "    for _ in range(random.randint(1, 3)):\n",
    "        sequence.append(random.choice(noise_events))\n",
    "    random.shuffle(sequence)\n",
    "    return sequence\n",
    "# Save to file\n",
    "with open(\"synthetic_sequences_large.txt\", \"w\") as f:\n",
    "    for _ in range(NUM_SEQUENCES):\n",
    "        seq = generate_sequence()\n",
    "        f.write(' '.join(seq) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd51a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With text simulating real data\n",
    "\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "NUM_SEQUENCES = 100  # Número de logs completos (altere conforme necessário)\n",
    "\n",
    "# Map events A-Z to realistic build logs\n",
    "event_to_log = {\n",
    "    'A': 'Scanning dependencies of target myapp',\n",
    "    'B': 'Building CXX object src/CMakeFiles/myapp.dir/main.cpp.o',\n",
    "    'C': 'Linking CXX executable bin/myapp',\n",
    "    'D': 'Scanning dependencies of target utils',\n",
    "    'E': 'Building CXX object src/CMakeFiles/utils.dir/utils.cpp.o',\n",
    "    'F': 'Scanning dependencies of target logger',\n",
    "    'G': 'Building CXX object src/CMakeFiles/logger.dir/logger.cpp.o',\n",
    "    'H': 'Linking CXX static library lib/liblogger.a',\n",
    "    'I': 'Building CXX object src/CMakeFiles/extra.dir/extra1.cpp.o',\n",
    "    'J': 'Building CXX object src/CMakeFiles/extra.dir/extra2.cpp.o',\n",
    "    'K': 'Building CXX object src/CMakeFiles/test.dir/test.cpp.o',\n",
    "    'L': 'Running tests...',\n",
    "    'M': 'Generating documentation with Doxygen',\n",
    "    'N': 'Packaging project into tar.gz',\n",
    "    'O': 'Copying resources to bin/',\n",
    "    'P': 'Building man pages',\n",
    "    'Q': 'Checking code style with clang-format',\n",
    "    'R': 'Building CXX object src/CMakeFiles/feature.dir/feature.cpp.o',\n",
    "    'S': 'Running static code analysis',\n",
    "    'T': 'Creating version header',\n",
    "    'U': 'Stripping binaries for size optimization',\n",
    "    'V': 'Archiving object files',\n",
    "    'W': 'Creating symlinks to shared libraries',\n",
    "    'X': '[INFO] Build environment: gcc 12.1, Ubuntu 22.04',\n",
    "    'Y': '[DEBUG] Cache hit for module config',\n",
    "    'Z': '[WARN] Deprecated API used in utils.cpp:23',\n",
    "}\n",
    "\n",
    "# Causal rules\n",
    "causal_rules = [\n",
    "    ['A', 'B', 'C'],\n",
    "    ['D', 'E'],\n",
    "    ['F', 'G', 'H'],\n",
    "]\n",
    "\n",
    "# Common cause pattern: H → I and H → J (but no direct I → J)\n",
    "common_causes = [('H', ['I', 'J'])]\n",
    "\n",
    "# Spurious reversed causality: J appears before I\n",
    "reversed_pairs = [('K', 'L')]  # L antes de K\n",
    "\n",
    "# Independent noisy events\n",
    "noise_events = ['X', 'Y', 'Z']\n",
    "\n",
    "# Creates a sequence of events according to the rules\n",
    "def generate_sequence():\n",
    "    sequence = []\n",
    "    # Causal chains\n",
    "    for chain in causal_rules:\n",
    "        sub = []\n",
    "        for e in chain:\n",
    "            if random.random() > 0.1:  # 10% chance to drop event\n",
    "                sub.append(e)\n",
    "        sequence.extend(sub)\n",
    "    # Common cause\n",
    "    for cause, effects in common_causes:\n",
    "        sequence.append(cause)\n",
    "        for e in effects:\n",
    "            if random.random() > 0.05:\n",
    "                sequence.append(e)\n",
    "    # Reversed causality\n",
    "    for a, b in reversed_pairs:\n",
    "        sequence.append(b)\n",
    "        sequence.append(a)\n",
    "    # Noise\n",
    "    for _ in range(random.randint(1, 3)):\n",
    "        sequence.append(random.choice(noise_events))\n",
    "    random.shuffle(sequence)\n",
    "    return sequence\n",
    "\n",
    "# Converts letters to logs with growing timestamps\n",
    "def sequence_to_timestamped_logs(sequence, base_time=None):\n",
    "    if base_time is None:\n",
    "        base_time = datetime.now().replace(microsecond=0)\n",
    "    current_time = base_time\n",
    "    logs = []\n",
    "    for event in sequence:\n",
    "        delta = timedelta(milliseconds=random.randint(1, 100))\n",
    "        current_time += delta\n",
    "        timestamp = current_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "        log_line = f\"{timestamp} {event_to_log[event]}\"\n",
    "        logs.append(log_line)\n",
    "    return logs\n",
    "\n",
    "# Save to file\n",
    "with open(\"synthetic_sequences.txt\", \"w\") as f:\n",
    "    for _ in range(NUM_SEQUENCES):\n",
    "        seq = generate_sequence()\n",
    "        logs = sequence_to_timestamped_logs(seq)\n",
    "        f.write('; '.join(logs) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "NUM_SEQUENCES = 100  # Número de logs completos\n",
    "## setting the number of lines as a parameter - initial 400 different templates\n",
    "## number of lines - 200k\n",
    "## fix the repeating timestamps\n",
    "## comparing the causalities with PC, other methods\n",
    "\n",
    "\n",
    "# Probability parameters (between 0 e 1)\n",
    "p_causal = 0.9       # Real causal links (ex: A → B → C)\n",
    "p_common = 0.95      # Common cause (H → I and H → J)\n",
    "p_spurious = 0.7     # Spurious causality (L → K)\n",
    "p_noise = 0.5        # Probability of including noise event (per event)\n",
    "\n",
    "# Map events A-Z to realistic build logs\n",
    "event_to_log = {\n",
    "    'A': 'Scanning dependencies of target myapp',\n",
    "    'B': 'Building CXX object src/CMakeFiles/myapp.dir/main.cpp.o',\n",
    "    'C': 'Linking CXX executable bin/myapp',\n",
    "    'D': 'Scanning dependencies of target utils',\n",
    "    'E': 'Building CXX object src/CMakeFiles/utils.dir/utils.cpp.o',\n",
    "    'F': 'Scanning dependencies of target logger',\n",
    "    'G': 'Building CXX object src/CMakeFiles/logger.dir/logger.cpp.o',\n",
    "    'H': 'Linking CXX static library lib/liblogger.a',\n",
    "    'I': 'Building CXX object src/CMakeFiles/extra.dir/extra1.cpp.o',\n",
    "    'J': 'Building CXX object src/CMakeFiles/extra.dir/extra2.cpp.o',\n",
    "    'K': 'Building CXX object src/CMakeFiles/test.dir/test.cpp.o',\n",
    "    'L': 'Running tests...',\n",
    "    'M': 'Generating documentation with Doxygen',\n",
    "    'N': 'Packaging project into tar.gz',\n",
    "    'O': 'Copying resources to bin/',\n",
    "    'P': 'Building man pages',\n",
    "    'Q': 'Checking code style with clang-format',\n",
    "    'R': 'Building CXX object src/CMakeFiles/feature.dir/feature.cpp.o',\n",
    "    'S': 'Running static code analysis',\n",
    "    'T': 'Creating version header',\n",
    "    'U': 'Stripping binaries for size optimization',\n",
    "    'V': 'Archiving object files',\n",
    "    'W': 'Creating symlinks to shared libraries',\n",
    "    'X': '[INFO] Build environment: gcc 12.1, Ubuntu 22.04',\n",
    "    'Y': '[DEBUG] Cache hit for module config',\n",
    "    'Z': '[WARN] Deprecated API used in utils.cpp:23',\n",
    "}\n",
    "\n",
    "# Rules\n",
    "causal_rules = [['A', 'B', 'C'], ['D', 'E'], ['F', 'G', 'H']]\n",
    "common_causes = [('H', ['I', 'J'])]\n",
    "reversed_pairs = [('K', 'L')]\n",
    "noise_events = ['X', 'Y', 'Z']\n",
    "\n",
    "def generate_sequence():\n",
    "    sequence = []\n",
    "\n",
    "    # Causal chains\n",
    "    for chain in causal_rules:\n",
    "        if random.random() < p_causal:\n",
    "            sub = []\n",
    "            for e in chain:\n",
    "                if random.random() < p_causal:\n",
    "                    sub.append(e)\n",
    "            sequence.extend(sub)\n",
    "\n",
    "    # Common cause\n",
    "    for cause, effects in common_causes:\n",
    "        if random.random() < p_common:\n",
    "            sequence.append(cause)\n",
    "            for e in effects:\n",
    "                if random.random() < p_common:\n",
    "                    sequence.append(e)\n",
    "\n",
    "    # Spurious reversed causality\n",
    "    for a, b in reversed_pairs:\n",
    "        if random.random() < p_spurious:\n",
    "            sequence.append(b)  # reversed on purpose\n",
    "            sequence.append(a)\n",
    "\n",
    "    # Noise\n",
    "    for e in noise_events:\n",
    "        if random.random() < p_noise:\n",
    "            sequence.append(e)\n",
    "\n",
    "    random.shuffle(sequence)\n",
    "    return sequence\n",
    "\n",
    "def sequence_to_timestamped_logs(sequence, base_time=None):\n",
    "    if base_time is None:\n",
    "        base_time = datetime.now().replace(microsecond=0)\n",
    "    current_time = base_time\n",
    "    logs = []\n",
    "    for event in sequence:\n",
    "        delta = timedelta(milliseconds=random.randint(1, 100))\n",
    "        current_time += delta\n",
    "        timestamp = current_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "        log_line = f\"{timestamp} {event_to_log[event]}\"\n",
    "        logs.append(log_line)\n",
    "    return logs\n",
    "\n",
    "# Save to file\n",
    "with open(\"synthetic_sequences.txt\", \"w\") as f:\n",
    "    for _ in range(NUM_SEQUENCES):\n",
    "        seq = generate_sequence()\n",
    "        logs = sequence_to_timestamped_logs(seq)\n",
    "        f.write('; '.join(logs) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc086473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Number of sequences\n",
    "NUM_SEQUENCES = 200000\n",
    "\n",
    "# Probability parameters\n",
    "p_causal   = 0.9\n",
    "p_common   = 0.95\n",
    "p_spurious = 0.7\n",
    "p_noise    = 0.5\n",
    "\n",
    "# Define 100 distinct actions\n",
    "actions = [\n",
    "    \"Scanning dependencies of target\",\n",
    "    \"Building CXX object\",\n",
    "    \"Linking CXX executable\",\n",
    "    \"Linking CXX static library\",\n",
    "    \"Running unit tests\",\n",
    "    \"Running integration tests\",\n",
    "    \"Generating documentation with Doxygen\",\n",
    "    \"Packaging project into tar.gz\",\n",
    "    \"Copying resources to bin/\",\n",
    "    \"Checking code style with clang-format\",\n",
    "    \"Running static code analysis\",\n",
    "    \"Stripping binaries for size optimization\",\n",
    "    \"Archiving object files\",\n",
    "    \"Creating symlinks to shared libraries\",\n",
    "    \"Cleaning build directory\",\n",
    "    \"Deploying to staging environment\",\n",
    "    \"Starting CI job\",\n",
    "    \"Stopping services\",\n",
    "    \"Initializing submodule\",\n",
    "    \"Updating submodules\",\n",
    "    \"Downloading artifacts\",\n",
    "    \"Uploading logs\",\n",
    "    \"Trying to compile\",\n",
    "    \"Generating new compilation file for\",\n",
    "    \"Checking linking errors\",\n",
    "    \"Monitoring memory usage\",\n",
    "    \"Starting performance profiling\",\n",
    "    \"Stopping performance profiling\",\n",
    "    \"Verifying digital signatures\",\n",
    "    \"Signing build artifact\",\n",
    "    \"Encrypting backup\",\n",
    "    \"Decrypting configuration\",\n",
    "    \"Validating JSON schemas\",\n",
    "    \"Formatting source code\",\n",
    "    \"Optimizing binary size\",\n",
    "    \"Compressing output files\",\n",
    "    \"Decompressing archives\",\n",
    "    \"Installing dependencies\",\n",
    "    \"Uninstalling old versions\",\n",
    "    \"Registering components\",\n",
    "    \"Deregistering services\",\n",
    "    \"Synchronizing build cache\",\n",
    "    \"Purging temporary files\",\n",
    "    \"Uploading build metrics\",\n",
    "    \"Reporting coverage statistics\",\n",
    "    \"Generating code coverage report\",\n",
    "    \"Running security scan\",\n",
    "    \"Uploading to artifact repository\",\n",
    "    \"Downloading container image\",\n",
    "    \"Building Docker image\",\n",
    "    \"Pushing Docker image\",\n",
    "    \"Pulling base image\",\n",
    "    \"Executing post-build script\",\n",
    "    \"Checking environment variables\",\n",
    "    \"Setting up build environment\",\n",
    "    \"Tearing down build environment\",\n",
    "    \"Merging build branches\",\n",
    "    \"Rebasing changes\",\n",
    "    \"Committing changes\",\n",
    "    \"Pushing commits to remote\",\n",
    "    \"Fetching updates from origin\",\n",
    "    \"Cloning repository\",\n",
    "    \"Checking out branch\",\n",
    "    \"Creating pull request\",\n",
    "    \"Merging pull request\",\n",
    "    \"Closing pull request\",\n",
    "    \"Running smoke tests\",\n",
    "    \"Running regression tests\",\n",
    "    \"Running performance tests\",\n",
    "    \"Validating API responses\",\n",
    "    \"Starting microservice\",\n",
    "    \"Stopping microservice\",\n",
    "    \"Connecting to database\",\n",
    "    \"Migrating database schema\",\n",
    "    \"Seeding database\",\n",
    "    \"Backing up database\",\n",
    "    \"Restoring database\",\n",
    "    \"Validating database integrity\",\n",
    "    \"Checking network connectivity\",\n",
    "    \"Initializing Docker container\",\n",
    "    \"Removing Docker container\",\n",
    "    \"Starting virtual machine\",\n",
    "    \"Stopping virtual machine\",\n",
    "    \"Mounting file system\",\n",
    "    \"Unmounting file system\",\n",
    "    \"Checking disk space\",\n",
    "    \"Cleaning package cache\",\n",
    "    \"Updating package index\",\n",
    "    \"Installing system packages\",\n",
    "    \"Removing orphaned packages\",\n",
    "    \"Generating changelog\",\n",
    "    \"Tagging release\",\n",
    "    \"Building release branch\",\n",
    "    \"Publishing release notes\",\n",
    "    \"Sending notification email\",\n",
    "    \"Triggering webhook\",\n",
    "    \"Restarting service\",\n",
    "    \"Verifying checksum\",\n",
    "    \"Calculating dependency tree\",\n",
    "    \"Generating UML diagrams\"\n",
    "]\n",
    "\n",
    "# 20 artifact patterns\n",
    "artifact_patterns = [\n",
    "    \"module_{n}\",\n",
    "    \"component_{n}.dir/file_{n}.cpp.o\",\n",
    "    \"output_{n}\",\n",
    "    \"index_{n}.html\",\n",
    "    \"lib_{n}.a\",\n",
    "    \"config_{n}.yaml\",\n",
    "    \"build_{n}.sh\",\n",
    "    \"test_suite_{n}.xml\",\n",
    "    \"pipeline_{n}.yml\",\n",
    "    \"build_{n}.log\",\n",
    "    \"header_{n}.h\",\n",
    "    \"libcomponent_{n}.so\",\n",
    "    \"env_{n}\",\n",
    "    \"service_{n}\",\n",
    "    \"service_{n}.log\",\n",
    "    \"tool_{n}\",\n",
    "    \"module_obj_{n}.o\",\n",
    "    \"cache_{n}.tmp\",\n",
    "    \"image_{n}\",\n",
    "    \"package_{n}.tar.gz\"\n",
    "]\n",
    "\n",
    "# Generate all action-artifact pairs and select 400\n",
    "all_pairs = [\n",
    "    (act, pattern, art_idx)\n",
    "    for art_idx, pattern in enumerate(artifact_patterns, start=1)\n",
    "    for act in actions\n",
    "]\n",
    "selected = random.sample(all_pairs, 400)\n",
    "\n",
    "# Map \"1\"..\"400\" to chosen templates\n",
    "event_to_log = {\n",
    "    str(idx): f\"{act} {pattern.format(n=art_idx)}\"\n",
    "    for idx, (act, pattern, art_idx) in enumerate(selected, start=1)\n",
    "}\n",
    "\n",
    "# Expanded rules\n",
    "causal_rules = [\n",
    "    [str(i), str(i+1), str(i+2)]\n",
    "    for i in range(1, 121, 3)\n",
    "]\n",
    "common_causes = [\n",
    "    (str(i), [str(i+1), str(i+2), str(i+3)])\n",
    "    for i in range(121, 201, 2)\n",
    "]\n",
    "reversed_pairs = [\n",
    "    (str(i), str(i+1))\n",
    "    for i in range(201, 281, 2)\n",
    "]\n",
    "noise_events = [str(i) for i in range(281, 321)]\n",
    "\n",
    "\n",
    "def generate_sequence():\n",
    "    seq = []\n",
    "\n",
    "    # causal chains\n",
    "    for chain in causal_rules:\n",
    "        if random.random() < p_causal:\n",
    "            for e in chain:\n",
    "                if random.random() < p_causal:\n",
    "                    seq.append(e)\n",
    "\n",
    "    # common cause\n",
    "    for cause, effects in common_causes:\n",
    "        if random.random() < p_common:\n",
    "            seq.append(cause)\n",
    "            for e in effects:\n",
    "                if random.random() < p_common:\n",
    "                    seq.append(e)\n",
    "\n",
    "    # spurious reversed\n",
    "    for a, b in reversed_pairs:\n",
    "        if random.random() < p_spurious:\n",
    "            seq.extend([b, a])\n",
    "\n",
    "    # noise\n",
    "    for e in noise_events:\n",
    "        if random.random() < p_noise:\n",
    "            seq.append(e)\n",
    "\n",
    "    random.shuffle(seq)\n",
    "    return seq\n",
    "\n",
    "\n",
    "def sequence_to_timestamped_line(seq):\n",
    "    # dynamic length 10–20\n",
    "    target_len = random.randint(10, 20)\n",
    "    if len(seq) > target_len:\n",
    "        seq = random.sample(seq, target_len)\n",
    "    else:\n",
    "        keys = list(event_to_log.keys())\n",
    "        while len(seq) < target_len:\n",
    "            seq.append(random.choice(keys))\n",
    "\n",
    "    timestamp = datetime.now().replace(microsecond=0).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    messages = '; '.join(event_to_log[e] for e in seq)\n",
    "    return f\"{timestamp} {messages}\"\n",
    "\n",
    "# Write out\n",
    "with open(\"synthetic_sequences.txt\", \"w\") as f:\n",
    "    for _ in range(NUM_SEQUENCES):\n",
    "        line = sequence_to_timestamped_line(generate_sequence())\n",
    "        f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503b2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "NUM_SEQUENCES = 200000\n",
    "\n",
    "p_causal   = 0.9\n",
    "p_common   = 0.95\n",
    "p_spurious = 0.7\n",
    "p_noise    = 0.5\n",
    "\n",
    "# Ações detalhadas realistas para maior variabilidade\n",
    "actions = [\n",
    "    \"Cloning repository\", \"Checking out branch\", \"Installing dependencies\", \"Verifying dependency integrity\",\n",
    "    \"Configuring build environment\", \"Building CXX object\", \"Building Java classes\", \"Compiling TypeScript files\",\n",
    "    \"Linking CXX executable\", \"Linking shared libraries\", \"Running unit tests\", \"Running integration tests\",\n",
    "    \"Generating code coverage report\", \"Reporting test results\", \"Checking code style\", \"Running linter checks\",\n",
    "    \"Analyzing static code\", \"Creating version header\", \"Compressing log files\", \"Uploading logs to S3\",\n",
    "    \"Triggering webhook\", \"Sending Slack notification\", \"Deploying to staging environment\", \"Deploying to production\",\n",
    "    \"Validating deployment\", \"Running smoke tests\", \"Starting CI job\", \"Finalizing CI job\",\n",
    "    \"Pushing Docker image\", \"Pulling Docker base image\", \"Tagging Docker image\", \"Cleaning Docker cache\",\n",
    "    \"Encrypting artifacts\", \"Decrypting configuration files\", \"Backing up database\", \"Restoring database\",\n",
    "    \"Migrating database schema\", \"Seeding database\", \"Checking database connectivity\", \"Restarting database service\",\n",
    "    \"Verifying checksums\", \"Running security scan\", \"Patching vulnerabilities\", \"Reviewing dependencies\",\n",
    "    \"Archiving build artifacts\", \"Publishing artifacts to repository\", \"Generating documentation with Doxygen\",\n",
    "    \"Converting markdown to HTML\", \"Publishing site\", \"Notifying release manager\", \"Syncing with GitHub\",\n",
    "    \"Merging pull request\", \"Rebasing branch\", \"Creating release notes\", \"Signing release packages\",\n",
    "    \"Verifying digital signatures\", \"Pushing changes to remote\", \"Creating git tag\", \"Verifying git tag signature\",\n",
    "    \"Running regression tests\", \"Running performance tests\", \"Measuring memory usage\", \"Analyzing CPU usage\",\n",
    "    \"Formatting source code\", \"Optimizing assets\", \"Uploading sourcemaps\", \"Tracking build metrics\",\n",
    "    \"Analyzing historical trends\", \"Creating Jira ticket\", \"Logging build statistics\", \"Sending report via email\",\n",
    "    \"Scanning for secrets in code\", \"Checking disk space\", \"Checking available memory\", \"Monitoring build agents\",\n",
    "    \"Syncing mirrors\", \"Rebooting build server\", \"Rebuilding failed jobs\", \"Creating new pipeline configuration\",\n",
    "    \"Triggering downstream jobs\", \"Validating Kubernetes manifests\", \"Deploying Helm charts\",\n",
    "    \"Verifying service health checks\", \"Logging health status\", \"Generating system diagnostics\",\n",
    "    \"Uploading crash reports\", \"Restarting failed containers\", \"Rebalancing workloads\",\n",
    "    \"[INFO] Build completed successfully\", \"[ERROR] Linker returned non-zero exit code\",\n",
    "    \"[WARN] Deprecated function used\", \"[DEBUG] Entering compilation loop\", \"[FATAL] Out of memory during linking stage\",\n",
    "    \"[TRACE] Dependency chain resolved\"\n",
    "]\n",
    "\n",
    "# Mais padrões de artefatos para aumentar diversidade\n",
    "artifact_patterns = [\n",
    "    \"module_{n}\", \"component_{n}.dir/file_{n}.cpp.o\", \"output_{n}\", \"index_{n}.html\", \"lib_{n}.a\",\n",
    "    \"config_{n}.yaml\", \"build_{n}.sh\", \"test_suite_{n}.xml\", \"pipeline_{n}.yml\", \"build_{n}.log\",\n",
    "    \"header_{n}.h\", \"libcomponent_{n}.so\", \"env_{n}\", \"service_{n}\", \"tool_{n}\", \"module_obj_{n}.o\",\n",
    "    \"cache_{n}.tmp\", \"image_{n}\", \"package_{n}.tar.gz\", \"resource_{n}.json\", \"docs_{n}.md\",\n",
    "    \"logfile_{n}.txt\", \"results_{n}.json\", \"job_{n}.status\", \"chart_{n}.yaml\", \"metrics_{n}.csv\",\n",
    "    \"secrets_{n}.env\", \"manifest_{n}.yaml\", \"analysis_{n}.rpt\", \"coverage_{n}.html\",\n",
    "    \"alert_{n}.json\", \"summary_{n}.txt\", \"buildspec_{n}.yml\", \"helm_{n}.tgz\", \"crashdump_{n}.log\",\n",
    "    \"trace_{n}.xml\", \"snapshot_{n}.img\", \"release_notes_{n}.md\", \"tasklog_{n}.txt\"\n",
    "]\n",
    "\n",
    "# Selecionar 400 combinações distintas\n",
    "all_pairs = [\n",
    "    (act, pattern, art_idx)\n",
    "    for art_idx, pattern in enumerate(artifact_patterns, start=1)\n",
    "    for act in actions\n",
    "]\n",
    "selected = random.sample(all_pairs, 400)\n",
    "\n",
    "event_to_log = {\n",
    "    str(idx): f\"{act} {pattern.format(n=art_idx)}\"\n",
    "    for idx, (act, pattern, art_idx) in enumerate(selected, start=1)\n",
    "}\n",
    "\n",
    "# Cadeias causais realistas ampliadas\n",
    "causal_chains_realistic = [\n",
    "    [\"Cloning repository\", \"Checking out branch\", \"Installing dependencies\"],\n",
    "    [\"Installing dependencies\", \"Configuring build environment\", \"Building CXX object\"],\n",
    "    [\"Building CXX object\", \"Linking CXX executable\", \"Running unit tests\"],\n",
    "    [\"Running unit tests\", \"Generating code coverage report\", \"Reporting test results\"],\n",
    "    [\"Running integration tests\", \"Validating deployment\", \"Running smoke tests\"],\n",
    "    [\"Migrating database schema\", \"Seeding database\", \"Checking database connectivity\"],\n",
    "    [\"Backing up database\", \"Restoring database\", \"Verifying checksums\"],\n",
    "    [\"Deploying to staging environment\", \"Deploying to production\", \"Validating deployment\"],\n",
    "    [\"Packaging project into tar.gz\", \"Uploading logs to S3\", \"Triggering webhook\"],\n",
    "    [\"Starting CI job\", \"Finalizing CI job\", \"Notifying release manager\"]\n",
    "]\n",
    "\n",
    "# Mapear essas a chaves de event_to_log\n",
    "reverse_lookup = {v: k for k, v in event_to_log.items()}\n",
    "causal_rules = []\n",
    "for chain in causal_chains_realistic:\n",
    "    try:\n",
    "        causal_rules.append([reverse_lookup[s] for s in chain])\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "common_causes = []\n",
    "if \"Cloning repository\" in reverse_lookup:\n",
    "    c = reverse_lookup[\"Cloning repository\"]\n",
    "    effects = [v for k, v in event_to_log.items() if \"Installing\" in v or \"Checking out\" in v or \"Building\" in v]\n",
    "    common_causes.append((c, [k for k, v in event_to_log.items() if v in effects][:4]))\n",
    "\n",
    "reversed_pairs = []\n",
    "for a, b in [(\"Running integration tests\", \"Deploying to production\"),\n",
    "             (\"Uploading logs to S3\", \"Triggering webhook\"),\n",
    "             (\"Generating documentation with Doxygen\", \"Publishing site\"),\n",
    "             (\"Migrating database schema\", \"Backing up database\")]:\n",
    "    if a in reverse_lookup and b in reverse_lookup:\n",
    "        reversed_pairs.append((reverse_lookup[b], reverse_lookup[a]))\n",
    "\n",
    "noise_events = [k for k, v in event_to_log.items() if any(err in v for err in [\"[ERROR]\", \"[WARN]\", \"[DEBUG]\", \"[FATAL]\", \"[TRACE]\"])]\n",
    "\n",
    "def generate_sequence():\n",
    "    seq = []\n",
    "    for chain in causal_rules:\n",
    "        if random.random() < p_causal:\n",
    "            for e in chain:\n",
    "                if random.random() < p_causal:\n",
    "                    seq.append(e)\n",
    "    for cause, effects in common_causes:\n",
    "        if random.random() < p_common:\n",
    "            seq.append(cause)\n",
    "            for e in effects:\n",
    "                if random.random() < p_common:\n",
    "                    seq.append(e)\n",
    "    for a, b in reversed_pairs:\n",
    "        if random.random() < p_spurious:\n",
    "            seq.extend([b, a])\n",
    "    for e in noise_events:\n",
    "        if random.random() < p_noise:\n",
    "            seq.append(e)\n",
    "    random.shuffle(seq)\n",
    "    return seq\n",
    "\n",
    "def sequence_to_timestamped_line(seq):\n",
    "    target_len = random.randint(10, 20)\n",
    "    if len(seq) > target_len:\n",
    "        seq = random.sample(seq, target_len)\n",
    "    else:\n",
    "        keys = list(event_to_log.keys())\n",
    "        while len(seq) < target_len:\n",
    "            seq.append(random.choice(keys))\n",
    "    timestamp = \"\"\n",
    "    messages = '\\n'.join(event_to_log[e] for e in seq)\n",
    "    return f\"<START>\\n{timestamp}\\n{messages}\\n<END>\"\n",
    "\n",
    "with open(\"synthetic_sequences.txt\", \"w\") as f:\n",
    "    for _ in range(NUM_SEQUENCES):\n",
    "        line = sequence_to_timestamped_line(generate_sequence())\n",
    "        f.write(line + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
