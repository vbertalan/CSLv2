{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610bf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vbertalan/.local/lib/python3.9/site-packages/causallearn/search/ConstraintBased/PC.py:36: UserWarning: The number of features is much larger than the sample size!\n",
      "  warnings.warn(\"The number of features is much larger than the sample size!\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.utils.cit import chisq\n",
    "import numpy as np\n",
    "\n",
    "def read_log_lines(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def build_windowed_dataset(log_lines, window_size=5):\n",
    "    windows = []\n",
    "    for i in range(len(log_lines) - window_size + 1):\n",
    "        window = log_lines[i:i+window_size]\n",
    "        windows.append(set(window))  # evita repeti√ß√£o dentro da janela\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_matrix = mlb.fit_transform(windows)\n",
    "    df = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
    "    return df, mlb.classes_\n",
    "\n",
    "def run_pc_and_export_csv(df, variable_names, output_path=\"pc_result.csv\", alpha=0.01):\n",
    "    X = df.to_numpy().astype(int)\n",
    "    cg = pc(data=X, alpha=alpha, indep_test=\"chisq\", uc_rule=0, verbose=False)\n",
    "\n",
    "    edges = []\n",
    "    n_vars = len(variable_names)\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_vars):\n",
    "            if cg.G.graph[i, j] == -1 and cg.G.graph[j, i] == 1:\n",
    "                # i ‚Üí j\n",
    "                edges.append((variable_names[i], variable_names[j]))\n",
    "\n",
    "    df_edges = pd.DataFrame(edges, columns=[\"source\", \"target\"])\n",
    "    df_edges.to_csv(output_path, index=False)\n",
    "    print(f\"Arquivo salvo em: {output_path} ({len(df_edges)} rela√ß√µes causais)\")\n",
    "    return df_edges\n",
    "\n",
    "\n",
    "# === Configura√ß√µes ===\n",
    "log_path = \"logs/logs_teste.log\"  # exemplo: \"/home/user/meu_log.log\"\n",
    "window_size = 5\n",
    "alpha = 0.01\n",
    "output_path = \"resultadosPC/causal_relations.csv\"\n",
    "\n",
    "# === Processamento ===\n",
    "log_lines = read_log_lines(log_path)\n",
    "df, variable_names = build_windowed_dataset(log_lines, window_size)\n",
    "df_result = run_pc_and_export_csv(df, variable_names, output_path, alpha=alpha)\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df_result.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.utils.cit import chisq\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def read_log_lines(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def choose_window_size(log_lines, frequent_templates, min_samples_per_feature=5, max_window=30):\n",
    "    n_features = len(frequent_templates)\n",
    "    n_lines = len(log_lines)\n",
    "\n",
    "    if n_features == 0:\n",
    "        raise ValueError(\"Nenhum evento com frequ√™ncia suficiente.\")\n",
    "\n",
    "    for window_size in range(max_window, 1, -1):\n",
    "        n_samples = n_lines - window_size + 1\n",
    "        if n_samples >= min_samples_per_feature * n_features:\n",
    "            return window_size\n",
    "    return 2\n",
    "\n",
    "def build_windowed_dataset(log_lines, window_size=None, min_freq=5):\n",
    "    counts = Counter(log_lines)\n",
    "    frequent_templates = {tpl for tpl, freq in counts.items() if freq >= min_freq}\n",
    "    filtered_lines = [line for line in log_lines if line in frequent_templates]\n",
    "\n",
    "    if len(frequent_templates) == 0:\n",
    "        raise ValueError(\"Nenhum template sobreviveu ao filtro de frequ√™ncia.\")\n",
    "\n",
    "    if window_size is None:\n",
    "        window_size = choose_window_size(filtered_lines, frequent_templates)\n",
    "\n",
    "    windows = []\n",
    "    for i in range(len(filtered_lines) - window_size + 1):\n",
    "        window = filtered_lines[i:i+window_size]\n",
    "        windows.append(set(window))\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_matrix = mlb.fit_transform(windows)\n",
    "    df = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
    "\n",
    "    n_samples = df.shape[0]\n",
    "    n_features = df.shape[1]\n",
    "    ratio = n_samples / n_features if n_features else 0\n",
    "\n",
    "    if ratio >= 10:\n",
    "        confidence = \"ALTA\"\n",
    "    elif ratio >= 5:\n",
    "        confidence = \"MODERADA\"\n",
    "    else:\n",
    "        confidence = \"BAIXA\"\n",
    "\n",
    "    return df, mlb.classes_, window_size, n_samples, n_features, ratio, confidence\n",
    "\n",
    "def run_pc_and_export(df, variable_names, csv_path=\"pc_result.csv\", report_path=\"pc_report.txt\", alpha=0.01):\n",
    "    X = df.to_numpy().astype(int)\n",
    "    cg = pc(data=X, alpha=alpha, indep_test=\"chisq\", uc_rule=0, verbose=False)\n",
    "\n",
    "    directed = []\n",
    "    bidirectional = []\n",
    "    undirected = []\n",
    "\n",
    "    n_vars = len(variable_names)\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_vars):\n",
    "            if i == j:\n",
    "                continue\n",
    "            a = cg.G.graph[i, j]\n",
    "            b = cg.G.graph[j, i]\n",
    "            if a == -1 and b == 1:\n",
    "                directed.append((variable_names[i], variable_names[j]))\n",
    "            elif a == 1 and b == 1:\n",
    "                bidirectional.append((variable_names[i], variable_names[j]))\n",
    "            elif a == -1 and b == -1:\n",
    "                undirected.append((variable_names[i], variable_names[j]))\n",
    "\n",
    "    # Criar dataframe completo\n",
    "    df_all = pd.DataFrame(directed + bidirectional + undirected,\n",
    "                          columns=[\"source\", \"target\"])\n",
    "    df_all[\"relation\"] = ([\"directed\"] * len(directed) +\n",
    "                          [\"bidirectional\"] * len(bidirectional) +\n",
    "                          [\"undirected\"] * len(undirected))\n",
    "\n",
    "    df_all.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Criar relat√≥rio\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"=== Relat√≥rio de Causalidade ===\\n\")\n",
    "        f.write(f\"Total de vari√°veis analisadas: {n_vars}\\n\")\n",
    "        f.write(f\"Arestas direcionadas: {len(directed)}\\n\")\n",
    "        f.write(f\"Arestas bidirecionais: {len(bidirectional)}\\n\")\n",
    "        f.write(f\"Arestas n√£o-direcionadas: {len(undirected)}\\n\")\n",
    "        f.write(f\"\\nCSV salvo em: {csv_path}\\n\")\n",
    "\n",
    "    print(f\"üíæ Arquivo CSV salvo em: {csv_path}\")\n",
    "    print(f\"üìù Relat√≥rio salvo em: {report_path}\")\n",
    "    return df_all\n",
    "\n",
    "log_path = \"/caminho/para/seu/logfile.log\"\n",
    "csv_path = \"relacoes_causais.csv\"\n",
    "report_path = \"relatorio.txt\"\n",
    "alpha = 0.01\n",
    "\n",
    "log_lines = read_log_lines(log_path)\n",
    "\n",
    "# Montar dataset\n",
    "df, variable_names, window_size, n_samples, n_features, ratio, confidence = build_windowed_dataset(\n",
    "    log_lines, window_size=None, min_freq=5\n",
    ")\n",
    "\n",
    "print(f\"üìè Window size escolhido: {window_size}\")\n",
    "print(f\"üìä {n_samples} janelas √ó {n_features} eventos √∫nicos ‚Üí raz√£o amostra/feature = {ratio:.2f}\")\n",
    "print(f\"üîé N√≠vel de confian√ßa estat√≠stica: {confidence}\")\n",
    "\n",
    "# Rodar algoritmo PC e salvar resultados\n",
    "df_result = run_pc_and_export(\n",
    "    df,\n",
    "    variable_names,\n",
    "    csv_path,\n",
    "    report_path,\n",
    "    alpha\n",
    ")\n",
    "\n",
    "df_result.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
